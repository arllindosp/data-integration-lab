{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62178a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f0353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e202c2d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810ff5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries required to clean, standardize, and prepare the dataset for futher analysis.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "start_time  = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e86f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† LOADING ITBI DATASETS - RECIFE\n",
      "========================================\n",
      "\n",
      "üìÖ Loading ITBI data 2023...\n",
      "   üîó URL: http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resou...\n",
      "   ‚è≥ Downloading file...\n",
      "   ‚úÖ Success: 12,669 records, 23 columns\n",
      "   üìä Data sample:\n",
      "      First neighborhoods: ['Encruzilhada', 'Encruzilhada', 'Encruzilhada']\n",
      "\n",
      "üìÖ Loading ITBI data 2024...\n",
      "   üîó URL: http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resou...\n",
      "   ‚è≥ Downloading file...\n",
      "   ‚úÖ Success: 15,242 records, 23 columns\n",
      "   üìä Data sample:\n",
      "      First neighborhoods: ['Encruzilhada', 'Encruzilhada', 'Encruzilhada']\n",
      "\n",
      "üìÖ Loading ITBI data 2025...\n",
      "   üîó URL: http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resou...\n",
      "   ‚è≥ Downloading file...\n",
      "   ‚úÖ Success: 7,206 records, 23 columns\n",
      "   üìä Data sample:\n",
      "      First neighborhoods: ['Encruzilhada', 'Encruzilhada', 'Encruzilhada']\n",
      "\n",
      "üîç VERIFication\n",
      "--------------------\n",
      "   ‚Ä¢ Total datasets loaded: 3\n",
      "   ‚Ä¢ Years included: ['2023', '2024', '2025']\n",
      "   ‚Ä¢ Expected datasets: 3\n",
      "\n",
      "üìä FINAL DATASET SUMMARY\n",
      "==============================\n",
      "   ‚Ä¢ Total records: 35,117\n",
      "   ‚Ä¢ Total columns: 23\n",
      "   ‚Ä¢ Years included: ['2023', '2024', '2025']\n",
      "   ‚Ä¢ 2023: Dataset loaded successfully\n",
      "   ‚Ä¢ 2024: Dataset loaded successfully\n",
      "   ‚Ä¢ 2025: Dataset loaded successfully\n",
      "\n",
      "üìã Sample data (first 3 rows):\n",
      "         bairro  tipo_imovel valor_avaliacao data_transacao\n",
      "0  Encruzilhada  Apartamento       505000,00     2025-01-08\n",
      "1  Encruzilhada  Apartamento       398109,72     2025-05-12\n",
      "2  Encruzilhada  Apartamento       790000,00     2025-04-14\n",
      "3  Encruzilhada  Apartamento       780000,00     2025-01-08\n",
      "\n",
      "‚úÖ Directory \"datasets\" is ready for use.\n",
      "‚úÖ ETL Extract phase completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path where datasets will be stored\n",
    "data_directory = \"datasets\"\n",
    "\n",
    "# Create the directory if it doesn't exist, avoiding errors if it already exists\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "# SIMPLIFIED VERSION - Basic loop for loading ITBI datasets\n",
    "\n",
    "# Define dataset URLs\n",
    "dataset_sources = [\n",
    "    (\"2023\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/d0c08a6f-4c27-423c-9219-8d13403816f4/download/itbi_2023.csv\"),\n",
    "    (\"2024\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/a36d548b-d705-496a-ac47-4ec36f068474/download/itbi_2024.csv\"),\n",
    "    (\"2025\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/5b582147-3935-459a-bbf7-ee623c22c97b/download/itbi_2025.csv\")\n",
    "]\n",
    "\n",
    "print(\"üè† LOADING ITBI DATASETS - RECIFE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simple loop to load each dataset\n",
    "load_success_count = 0\n",
    "all_records_total = 0\n",
    "all_columns_total = 0\n",
    "years_loaded = []\n",
    "data_storage = {}  # Dictionary to store the datasets\n",
    "\n",
    "for load_year, data_url in dataset_sources:\n",
    "    print(f\"\\nüìÖ Loading ITBI data {load_year}...\")\n",
    "    print(f\"   üîó URL: {data_url[:80]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Try to load the CSV\n",
    "        print(f\"   ‚è≥ Downloading file...\")\n",
    "        temp_dataframe = pd.read_csv(data_url, sep=';', encoding='utf-8')\n",
    "        \n",
    "        # Check if DataFrame is not empty\n",
    "        if temp_dataframe.empty:\n",
    "            raise ValueError(\"Dataset loaded is empty\")\n",
    "        \n",
    "        # Check if it has the expected columns\n",
    "        required_columns = ['bairro', 'tipo_imovel', 'valor_avaliacao', 'data_transacao']\n",
    "        missing_columns = [col for col in required_columns if col not in temp_dataframe.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"   ‚ö†Ô∏è  Warning: Missing columns: {missing_columns}\")\n",
    "        \n",
    "        # Add year column\n",
    "        temp_dataframe['year'] = int(load_year)\n",
    "        \n",
    "        # Show basic information\n",
    "        current_records = len(temp_dataframe)\n",
    "        current_columns = len(temp_dataframe.columns)\n",
    "        \n",
    "        # Add to general totals\n",
    "        all_records_total += current_records\n",
    "        all_columns_total = current_columns  # Assume all have the same number of columns\n",
    "        years_loaded.append(load_year)\n",
    "        \n",
    "        # Save dataset in dictionary for later manipulation\n",
    "        data_storage[load_year] = temp_dataframe.copy()  # Create an independent copy\n",
    "        \n",
    "        print(f\"   ‚úÖ Success: {current_records:,} records, {current_columns} columns\")\n",
    "        print(f\"   üìä Data sample:\")\n",
    "        \n",
    "        # Check if 'bairro' column exists before showing\n",
    "        if 'bairro' in temp_dataframe.columns:\n",
    "            sample_neighborhoods = temp_dataframe['bairro'].head(3).tolist()\n",
    "            print(f\"      First neighborhoods: {sample_neighborhoods}\")\n",
    "            del sample_neighborhoods\n",
    "        else:\n",
    "            first_column_sample = temp_dataframe.iloc[:3, 0].tolist()\n",
    "            print(f\"      First 3 rows of first column: {first_column_sample}\")\n",
    "            del first_column_sample\n",
    "        \n",
    "        load_success_count += 1\n",
    "        del current_records, current_columns\n",
    "        \n",
    "    except Exception as load_error:\n",
    "        print(f\"   ‚ùå Error loading data for {load_year}: {type(load_error).__name__}\")\n",
    "        print(f\"      Details: {str(load_error)}\")\n",
    "        del load_error\n",
    "\n",
    "# Clean up loop variables\n",
    "del load_year, data_url, temp_dataframe, required_columns, missing_columns\n",
    "\n",
    "print(f\"\\nüîç VERIFication\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"   ‚Ä¢ Total datasets loaded: {load_success_count}\")\n",
    "print(f\"   ‚Ä¢ Years included: {years_loaded}\")\n",
    "print(f\"   ‚Ä¢ Expected datasets: 3\")\n",
    "print()\n",
    "\n",
    "print(f\"üìä FINAL DATASET SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"   ‚Ä¢ Total records: {all_records_total:,}\")\n",
    "print(f\"   ‚Ä¢ Total columns: {all_columns_total}\")\n",
    "print(f\"   ‚Ä¢ Years included: {years_loaded}\")\n",
    "\n",
    "print(f\"   ‚Ä¢ 2023: Dataset loaded successfully\")\n",
    "print(f\"   ‚Ä¢ 2024: Dataset loaded successfully\") \n",
    "print(f\"   ‚Ä¢ 2025: Dataset loaded successfully\")\n",
    "\n",
    "# Access specific datasets with intermediate variables\n",
    "dataset_2023 = data_storage['2023']\n",
    "dataset_2024 = data_storage['2024']\n",
    "dataset_2025 = data_storage['2025']\n",
    "\n",
    "print(f\"\\nüìã Sample data (first 3 rows):\")\n",
    "sample_data = dataset_2025[['bairro', 'tipo_imovel', 'valor_avaliacao', 'data_transacao']].head(4)\n",
    "print(sample_data)\n",
    "\n",
    "print(f'\\n‚úÖ Directory \"{data_directory}\" is ready for use.')\n",
    "print(\"‚úÖ ETL Extract phase completed successfully!\")\n",
    "\n",
    "# Clean up all intermediate variables\n",
    "del load_success_count, all_records_total, all_columns_total, years_loaded\n",
    "del dataset_2023, dataset_2024, dataset_2025, sample_data\n",
    "\n",
    "# Rename final variables for consistency\n",
    "dataset_directory = data_directory\n",
    "datasets_dict = data_storage\n",
    "del data_directory, data_storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f036df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SAVING DATASETS TO FILES AND CREATING ZIP ARCHIVE\n",
      "=======================================================\n",
      "   ‚úÖ Saved: itbi_2023.csv\n",
      "   ‚úÖ Saved: itbi_2024.csv\n",
      "   ‚úÖ Saved: itbi_2025.csv\n",
      "\n",
      "‚úÖ ZIP ARCHIVE CREATED SUCCESSFULLY!\n",
      "   üì¶ Filename: itbi_datasets_recife.zip\n",
      "   üìÅ Size: 0.91 MB\n",
      "   üóÉÔ∏è  Files in ZIP: 3\n",
      "   üìÇ Location: datasets\\itbi_datasets_recife.zip\n"
     ]
    }
   ],
   "source": [
    "# Save dataframes as CSV files and create ZIP archive\n",
    "\n",
    "header_message = \"üíæ SAVING DATASETS TO FILES AND CREATING ZIP ARCHIVE\"\n",
    "separator_line = \"=\" * 55\n",
    "\n",
    "print(header_message)\n",
    "print(separator_line)\n",
    "\n",
    "# Clean up header variables immediately\n",
    "del header_message, separator_line\n",
    "\n",
    "# Initialize control variables\n",
    "csv_files_list = []\n",
    "save_successful = True\n",
    "\n",
    "# Create CSV files with proper variable management\n",
    "for dataset_year, dataset_df in datasets_dict.items():\n",
    "    # Create filename using intermediate variables\n",
    "    csv_filename = f\"itbi_{dataset_year}.csv\"\n",
    "    csv_filepath = os.path.join(dataset_directory, csv_filename)\n",
    "    \n",
    "    try:\n",
    "        # Save to CSV\n",
    "        dataset_df.to_csv(csv_filepath, sep=';', encoding='utf-8', index=False)\n",
    "        csv_files_list.append(csv_filepath)\n",
    "    except Exception as save_error:\n",
    "        # Use intermediate variable for error message\n",
    "        error_msg = f\"   ‚ùå Failed to save: {csv_filename}\"\n",
    "        print(error_msg)\n",
    "        save_successful = False\n",
    "        del save_error, error_msg\n",
    "    \n",
    "    # Clean up loop variables immediately\n",
    "    del csv_filename, csv_filepath\n",
    "\n",
    "# Clean up loop variables completely\n",
    "del dataset_year, dataset_df\n",
    "\n",
    "# Print success messages outside the loop to avoid duplicates\n",
    "for file_path in csv_files_list:\n",
    "    # Use intermediate variable for filename\n",
    "    saved_filename = os.path.basename(file_path)\n",
    "    success_msg = f\"   ‚úÖ Saved: {saved_filename}\"\n",
    "    print(success_msg)\n",
    "    del saved_filename, success_msg\n",
    "\n",
    "# CRITICAL: Clean up the loop variable\n",
    "del file_path\n",
    "\n",
    "# Create ZIP archive if CSV files were created successfully\n",
    "if csv_files_list and save_successful:\n",
    "    # Create intermediate variables for ZIP creation\n",
    "    zip_filename = \"itbi_datasets_recife.zip\"\n",
    "    zip_filepath = os.path.join(dataset_directory, zip_filename)\n",
    "    \n",
    "    try:\n",
    "        # Create ZIP with managed variables\n",
    "        with zipfile.ZipFile(zip_filepath, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            for source_file in csv_files_list:\n",
    "                target_filename = os.path.basename(source_file)\n",
    "                zip_file.write(source_file, target_filename)\n",
    "                del target_filename\n",
    "            del source_file\n",
    "        \n",
    "        # Verify and show results with managed variables\n",
    "        if os.path.exists(zip_filepath):\n",
    "            # Calculate file size using intermediate variables\n",
    "            file_size_bytes = os.path.getsize(zip_filepath)\n",
    "            file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "            \n",
    "            with zipfile.ZipFile(zip_filepath, 'r') as zip_reader:\n",
    "                zip_contents = zip_reader.namelist()\n",
    "                files_in_zip = len(zip_contents)\n",
    "            \n",
    "            # Create all success messages using intermediate variables\n",
    "            success_header = \"\\n‚úÖ ZIP ARCHIVE CREATED SUCCESSFULLY!\"\n",
    "            filename_line = f\"   üì¶ Filename: {zip_filename}\"\n",
    "            size_line = f\"   üìÅ Size: {file_size_mb:.2f} MB\"\n",
    "            files_line = f\"   üóÉÔ∏è  Files in ZIP: {files_in_zip}\"\n",
    "            location_line = f\"   üìÇ Location: {zip_filepath}\"\n",
    "            \n",
    "            print(success_header)\n",
    "            print(filename_line)\n",
    "            print(size_line)\n",
    "            print(files_line)\n",
    "            print(location_line)\n",
    "            \n",
    "            # Clean up all verification variables immediately\n",
    "            del file_size_bytes, file_size_mb, zip_contents, files_in_zip\n",
    "            del success_header, filename_line, size_line, files_line, location_line\n",
    "        else:\n",
    "            # Use intermediate variable for error message\n",
    "            zip_not_created_msg = \"   ‚ùå Error: ZIP file was not created\"\n",
    "            print(zip_not_created_msg)\n",
    "            del zip_not_created_msg\n",
    "            \n",
    "    except Exception as zip_error:\n",
    "        # Use intermediate variables for error handling\n",
    "        error_details = str(zip_error)\n",
    "        zip_error_msg = f\"   ‚ùå Error creating ZIP: {error_details}\"\n",
    "        print(zip_error_msg)\n",
    "        del zip_error, error_details, zip_error_msg\n",
    "        \n",
    "    # Clean up ZIP variables immediately\n",
    "    del zip_filename, zip_filepath\n",
    "else:\n",
    "    # Use intermediate variable for failure message\n",
    "    no_zip_msg = \"\\n‚ùå Cannot create ZIP: No CSV files or save errors occurred\"\n",
    "    print(no_zip_msg)\n",
    "    del no_zip_msg\n",
    "\n",
    "# Final comprehensive cleanup\n",
    "del csv_files_list, save_successful\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27845df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['logradouro', 'numero', 'complemento', 'valor_avaliacao', 'bairro',\n",
       "       'cidade', 'uf', 'ano_construcao', 'area_terreno', 'area_construida',\n",
       "       'fracao_ideal', 'padrao_acabamento', 'tipo_construcao', 'tipo_ocupacao',\n",
       "       'data_transacao', 'estado_conservacao', 'tipo_imovel', 'sfh',\n",
       "       'cod_logradouro', 'latitude', 'longitude', 'ano', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's take a good look at the tables and their nomenclature structure.\n",
    "# After analyzing the datasets, we can confirm that all tables follow good naming standards:\n",
    "# snake_case convention, descriptive names, Portuguese language consistency, no special characters,\n",
    "# logical grouping, and standardized separators. These naming conventions ensure database \n",
    "# compatibility, readability, and maintainability across different systems and programming environments.\n",
    "# However, the 'sfh' acronym lacks clarity and context, making it difficult for users to understand\n",
    "# its meaning without domain knowledge. To improve data documentation and usability, we will rename\n",
    "# this column to 'valores_financiados_sfh' providing explicit context about financed values.\n",
    "datasets_dict['2023'].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0846a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming renaming sfh column in order to improve understanding \n",
    "for year, df in datasets_dict.items():\n",
    "    new_df = df.rename(columns = {'sfh':'valores_financiados_sfh'})\n",
    "    datasets_dict[year] = new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7c9d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫ Data Health Check - Missing Values Diagnostic & Investigation\n",
      "=================================================================\n",
      "\n",
      "üìÖ Dataset 2023:\n",
      "--------------------\n",
      "  üîç Found 3 columns with missing values:\n",
      "      ‚Ä¢ complemento: 1,320 nulls \n",
      "      ‚Ä¢ latitude: 3,402 nulls \n",
      "      ‚Ä¢ longitude: 3,402 nulls \n",
      "\n",
      "üìÖ Dataset 2024:\n",
      "--------------------\n",
      "  üîç Found 3 columns with missing values:\n",
      "      ‚Ä¢ complemento: 1,443 nulls \n",
      "      ‚Ä¢ latitude: 5,619 nulls \n",
      "      ‚Ä¢ longitude: 5,619 nulls \n",
      "\n",
      "üìÖ Dataset 2025:\n",
      "--------------------\n",
      "  üîç Found 3 columns with missing values:\n",
      "      ‚Ä¢ complemento: 576 nulls \n",
      "      ‚Ä¢ latitude: 2,623 nulls \n",
      "      ‚Ä¢ longitude: 2,623 nulls \n",
      "\n",
      "üìã Final diagnosis:\n",
      "There is a total of 3 datasets with missing values out of 3 total datasets.\n"
     ]
    }
   ],
   "source": [
    "# Null values analysis \n",
    "print(\"ü©∫ Data Health Check - Missing Values Diagnostic & Investigation\")\n",
    "print(\"=\" * 65)\n",
    "missing_datasets = 0\n",
    "for year, df in datasets_dict.items():\n",
    "    print(f\"\\nüìÖ Dataset {year}:\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    null_summary = df.isna().sum()\n",
    "    columns_with_nulls = null_summary[null_summary > 0]\n",
    "    \n",
    "    if len(columns_with_nulls.index.tolist()) > 0:\n",
    "        \n",
    "        missing_datasets += 1\n",
    "        print(f\"  üîç Found {len(columns_with_nulls)} columns with missing values:\")\n",
    "        \n",
    "        for column_name, null_count in columns_with_nulls.items():\n",
    "            print(f\"      ‚Ä¢ {column_name}: {null_count:,} nulls \")\n",
    "            \n",
    "    else:\n",
    "        print(\"   ‚úÖ No missing values found - Dataset is complete!\")\n",
    "\n",
    "\n",
    "print(\"\\nüìã Final diagnosis:\")\n",
    "print(f'There is a total of {missing_datasets} datasets with missing values out of {len(datasets_dict)} total datasets.')\n",
    "\n",
    "# NEXT STEP: DATA CLEANING AND NULL VALUES TREATMENT\n",
    "# Now that we've identified null values in some datasets, we need to perform cleaning\n",
    "# and removal of these missing values to prevent issues during subsequent analysis.\n",
    "# Null values can cause errors in statistical calculations, visualizations, and data modeling.\n",
    "# Proper treatment of these values is essential for ETL pipeline integrity and reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7dae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12669 entries, 0 to 12668\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   logradouro               12669 non-null  object \n",
      " 1   numero                   12669 non-null  int64  \n",
      " 2   complemento              11349 non-null  object \n",
      " 3   valor_avaliacao          12669 non-null  object \n",
      " 4   bairro                   12669 non-null  object \n",
      " 5   ano_construcao           12669 non-null  int64  \n",
      " 6   area_terreno             12669 non-null  object \n",
      " 7   area_construida          12669 non-null  object \n",
      " 8   fracao_ideal             12669 non-null  object \n",
      " 9   padrao_acabamento        12669 non-null  object \n",
      " 10  tipo_construcao          12669 non-null  object \n",
      " 11  tipo_ocupacao            12669 non-null  object \n",
      " 12  data_transacao           12669 non-null  object \n",
      " 13  estado_conservacao       12669 non-null  object \n",
      " 14  tipo_imovel              12669 non-null  object \n",
      " 15  valores_financiados_sfh  12669 non-null  object \n",
      " 16  cod_logradouro           12669 non-null  int64  \n",
      " 17  latitude                 9267 non-null   float64\n",
      " 18  longitude                9267 non-null   float64\n",
      " 19  ano                      12669 non-null  int64  \n",
      " 20  year                     12669 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(14)\n",
      "memory usage: 2.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15242 entries, 0 to 15241\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   logradouro               15242 non-null  object \n",
      " 1   numero                   15242 non-null  int64  \n",
      " 2   complemento              13799 non-null  object \n",
      " 3   valor_avaliacao          15242 non-null  object \n",
      " 4   bairro                   15242 non-null  object \n",
      " 5   ano_construcao           15242 non-null  int64  \n",
      " 6   area_terreno             15242 non-null  object \n",
      " 7   area_construida          15242 non-null  object \n",
      " 8   fracao_ideal             15242 non-null  object \n",
      " 9   padrao_acabamento        15242 non-null  object \n",
      " 10  tipo_construcao          15242 non-null  object \n",
      " 11  tipo_ocupacao            15242 non-null  object \n",
      " 12  data_transacao           15242 non-null  object \n",
      " 13  estado_conservacao       15242 non-null  object \n",
      " 14  tipo_imovel              15242 non-null  object \n",
      " 15  valores_financiados_sfh  15242 non-null  object \n",
      " 16  cod_logradouro           15242 non-null  int64  \n",
      " 17  latitude                 9623 non-null   float64\n",
      " 18  longitude                9623 non-null   float64\n",
      " 19  ano                      15242 non-null  int64  \n",
      " 20  year                     15242 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(14)\n",
      "memory usage: 2.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7206 entries, 0 to 7205\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   logradouro               7206 non-null   object \n",
      " 1   numero                   7206 non-null   int64  \n",
      " 2   complemento              6630 non-null   object \n",
      " 3   valor_avaliacao          7206 non-null   object \n",
      " 4   bairro                   7206 non-null   object \n",
      " 5   ano_construcao           7206 non-null   int64  \n",
      " 6   area_terreno             7206 non-null   object \n",
      " 7   area_construida          7206 non-null   object \n",
      " 8   fracao_ideal             7206 non-null   object \n",
      " 9   padrao_acabamento        7206 non-null   object \n",
      " 10  tipo_construcao          7206 non-null   object \n",
      " 11  tipo_ocupacao            7206 non-null   object \n",
      " 12  data_transacao           7206 non-null   object \n",
      " 13  estado_conservacao       7206 non-null   object \n",
      " 14  tipo_imovel              7206 non-null   object \n",
      " 15  valores_financiados_sfh  7206 non-null   object \n",
      " 16  cod_logradouro           7206 non-null   int64  \n",
      " 17  latitude                 4583 non-null   float64\n",
      " 18  longitude                4583 non-null   float64\n",
      " 19  ano                      7206 non-null   int64  \n",
      " 20  year                     7206 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(14)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# COLUMN OPTIMIZATION: REMOVING REDUNDANT GEOGRAPHIC COLUMNS\n",
    "# We will drop the 'cidade' and 'uf' columns as they contain only uniform values across all records\n",
    "# (Recife and PE respectively). Since our analysis focuses specifically on ITBI data from Recife's\n",
    "# urban region within Pernambuco state, these columns provide no analytical value or variation.\n",
    "# Removing these redundant columns optimizes memory usage and simplifies the dataset structure\n",
    "# without losing any meaningful information for our geographic scope of analysis.\n",
    "\n",
    "for year, df in datasets_dict.items():\n",
    "    df = df.drop([\"cidade\", \"uf\"], axis =1)\n",
    "    df.info()\n",
    "    datasets_dict[year] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f9f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    av norte miguel arraes de alencar\n",
      "1    av norte miguel arraes de alencar\n",
      "2                   rua belmiro corr√™a\n",
      "3                   rua belmiro corr√™a\n",
      "4                   rua belmiro corr√™a\n",
      "5                   rua belmiro corr√™a\n",
      "6                   rua belmiro corr√™a\n",
      "7                   rua belmiro corr√™a\n",
      "8                   rua belmiro corr√™a\n",
      "9                   rua belmiro corr√™a\n",
      "Name: logradouro, dtype: object\n",
      "0    3071\n",
      "1    3029\n",
      "2     133\n",
      "3     133\n",
      "4     133\n",
      "5     133\n",
      "6     133\n",
      "7     133\n",
      "8     109\n",
      "9     109\n",
      "Name: numero, dtype: int64\n",
      "0          NaN\n",
      "1          NaN\n",
      "2    apto 0001\n",
      "3    apto 0001\n",
      "4    apto 0002\n",
      "5    apto 0003\n",
      "6    apto 0004\n",
      "7    apto 0005\n",
      "8          NaN\n",
      "9          NaN\n",
      "Name: complemento, dtype: object\n",
      "0    1068562,63\n",
      "1    1500000,00\n",
      "2     110000,00\n",
      "3     110000,00\n",
      "4     110000,00\n",
      "5     110000,00\n",
      "6     110000,00\n",
      "7     110000,00\n",
      "8    4900000,00\n",
      "9    4900000,00\n",
      "Name: valor_avaliacao, dtype: object\n",
      "0    Encruzilhada\n",
      "1    Encruzilhada\n",
      "2    Encruzilhada\n",
      "3    Encruzilhada\n",
      "4    Encruzilhada\n",
      "5    Encruzilhada\n",
      "6    Encruzilhada\n",
      "7    Encruzilhada\n",
      "8    Encruzilhada\n",
      "9    Encruzilhada\n",
      "Name: bairro, dtype: object\n",
      "0    1997\n",
      "1    1957\n",
      "2    1970\n",
      "3    1970\n",
      "4    1970\n",
      "5    1970\n",
      "6    1970\n",
      "7    1970\n",
      "8    1951\n",
      "9    1951\n",
      "Name: ano_construcao, dtype: int64\n",
      "0     438,0\n",
      "1    779,33\n",
      "2    562,05\n",
      "3    562,05\n",
      "4    562,05\n",
      "5    562,05\n",
      "6    562,05\n",
      "7    562,05\n",
      "8    439,28\n",
      "9    439,28\n",
      "Name: area_terreno, dtype: object\n",
      "0     511,0\n",
      "1    582,44\n",
      "2     121,0\n",
      "3     121,0\n",
      "4      81,0\n",
      "5      81,0\n",
      "6      81,0\n",
      "7      81,0\n",
      "8    343,23\n",
      "9    343,23\n",
      "Name: area_construida, dtype: object\n",
      "0        1,0\n",
      "1        1,0\n",
      "2    0,27191\n",
      "3    0,27191\n",
      "4    0,18202\n",
      "5    0,18202\n",
      "6    0,18202\n",
      "7    0,18202\n",
      "8        1,0\n",
      "9        1,0\n",
      "Name: fracao_ideal, dtype: object\n",
      "0      M√©dio\n",
      "1      M√©dio\n",
      "2    Simples\n",
      "3    Simples\n",
      "4    Simples\n",
      "5    Simples\n",
      "6    Simples\n",
      "7    Simples\n",
      "8      M√©dio\n",
      "9      M√©dio\n",
      "Name: padrao_acabamento, dtype: object\n",
      "0                         Galp√£o\n",
      "1                           Casa\n",
      "2    Apartamento <= 4 Pavimentos\n",
      "3    Apartamento <= 4 Pavimentos\n",
      "4    Apartamento <= 4 Pavimentos\n",
      "5    Apartamento <= 4 Pavimentos\n",
      "6    Apartamento <= 4 Pavimentos\n",
      "7    Apartamento <= 4 Pavimentos\n",
      "8                           Casa\n",
      "9                           Casa\n",
      "Name: tipo_construcao, dtype: object\n",
      "0    COMERCIAL COM LIXO ORGANICO\n",
      "1    COMERCIAL SEM LIXO ORGANICO\n",
      "2                    RESIDENCIAL\n",
      "3                    RESIDENCIAL\n",
      "4                    RESIDENCIAL\n",
      "5                    RESIDENCIAL\n",
      "6                    RESIDENCIAL\n",
      "7                    RESIDENCIAL\n",
      "8                    RESIDENCIAL\n",
      "9                    RESIDENCIAL\n",
      "Name: tipo_ocupacao, dtype: object\n",
      "0    2023-12-21\n",
      "1    2023-11-17\n",
      "2    2023-09-26\n",
      "3    2023-09-22\n",
      "4    2023-09-22\n",
      "5    2023-09-22\n",
      "6    2023-09-26\n",
      "7    2023-09-22\n",
      "8    2023-09-26\n",
      "9    2023-09-26\n",
      "Name: data_transacao, dtype: object\n",
      "0    Regular\n",
      "1    Regular\n",
      "2        Bom\n",
      "3        Bom\n",
      "4        Bom\n",
      "5        Bom\n",
      "6        Bom\n",
      "7        Bom\n",
      "8        Bom\n",
      "9        Bom\n",
      "Name: estado_conservacao, dtype: object\n",
      "0         Galp√£o\n",
      "1           Casa\n",
      "2    Apartamento\n",
      "3    Apartamento\n",
      "4    Apartamento\n",
      "5    Apartamento\n",
      "6    Apartamento\n",
      "7    Apartamento\n",
      "8           Casa\n",
      "9           Casa\n",
      "Name: tipo_imovel, dtype: object\n",
      "0    0,00\n",
      "1    0,00\n",
      "2    0,00\n",
      "3    0,00\n",
      "4    0,00\n",
      "5    0,00\n",
      "6    0,00\n",
      "7    0,00\n",
      "8    0,00\n",
      "9    0,00\n",
      "Name: valores_financiados_sfh, dtype: object\n",
      "0    46540\n",
      "1    46540\n",
      "2    10715\n",
      "3    10715\n",
      "4    10715\n",
      "5    10715\n",
      "6    10715\n",
      "7    10715\n",
      "8    10715\n",
      "9    10715\n",
      "Name: cod_logradouro, dtype: int64\n",
      "0   -8.034273\n",
      "1   -8.034435\n",
      "2   -8.035013\n",
      "3   -8.035013\n",
      "4   -8.035013\n",
      "5   -8.035013\n",
      "6   -8.035013\n",
      "7   -8.035013\n",
      "8   -8.035165\n",
      "9   -8.035165\n",
      "Name: latitude, dtype: float64\n",
      "0   -34.896337\n",
      "1   -34.896335\n",
      "2   -34.895903\n",
      "3   -34.895903\n",
      "4   -34.895903\n",
      "5   -34.895903\n",
      "6   -34.895903\n",
      "7   -34.895903\n",
      "8   -34.895961\n",
      "9   -34.895961\n",
      "Name: longitude, dtype: float64\n",
      "0    2023\n",
      "1    2023\n",
      "2    2023\n",
      "3    2023\n",
      "4    2023\n",
      "5    2023\n",
      "6    2023\n",
      "7    2023\n",
      "8    2023\n",
      "9    2023\n",
      "Name: ano, dtype: int64\n",
      "0    2023\n",
      "1    2023\n",
      "2    2023\n",
      "3    2023\n",
      "4    2023\n",
      "5    2023\n",
      "6    2023\n",
      "7    2023\n",
      "8    2023\n",
      "9    2023\n",
      "Name: year, dtype: int64\n",
      "0    av norte miguel arraes de alencar\n",
      "1    av norte miguel arraes de alencar\n",
      "2    av norte miguel arraes de alencar\n",
      "3                     rua caio pereira\n",
      "4                     rua caio pereira\n",
      "5                     rua caio pereira\n",
      "6                     rua caio pereira\n",
      "7                     rua caio pereira\n",
      "8                     rua caio pereira\n",
      "9                     rua caio pereira\n",
      "Name: logradouro, dtype: object\n",
      "0    3071\n",
      "1    3029\n",
      "2    3029\n",
      "3     375\n",
      "4     375\n",
      "5     375\n",
      "6     375\n",
      "7     800\n",
      "8     800\n",
      "9     800\n",
      "Name: numero, dtype: int64\n",
      "0                               NaN\n",
      "1                               NaN\n",
      "2                               NaN\n",
      "3    apto 503 edf luar do rosarinho\n",
      "4    apto 602 edf luar do rosarinho\n",
      "5    apto 801 edf luar do rosarinho\n",
      "6    apto 203 edf luar do rosarinho\n",
      "7      apto 1901 edf sainte juliana\n",
      "8       apto 902 edf sainte juliana\n",
      "9       apto 203 edf sainte juliana\n",
      "Name: complemento, dtype: object\n",
      "0    1068562,63\n",
      "1    1951000,00\n",
      "2    1500000,00\n",
      "3     402544,22\n",
      "4     405198,63\n",
      "5     409994,56\n",
      "6     395501,75\n",
      "7     700000,00\n",
      "8     790000,00\n",
      "9     680000,00\n",
      "Name: valor_avaliacao, dtype: object\n",
      "0    Encruzilhada\n",
      "1    Encruzilhada\n",
      "2    Encruzilhada\n",
      "3    Encruzilhada\n",
      "4    Encruzilhada\n",
      "5    Encruzilhada\n",
      "6    Encruzilhada\n",
      "7    Encruzilhada\n",
      "8    Encruzilhada\n",
      "9    Encruzilhada\n",
      "Name: bairro, dtype: object\n",
      "0    1997\n",
      "1    1957\n",
      "2    1957\n",
      "3    2007\n",
      "4    2007\n",
      "5    2007\n",
      "6    2007\n",
      "7    2017\n",
      "8    2017\n",
      "9    2017\n",
      "Name: ano_construcao, dtype: int64\n",
      "0      438,0\n",
      "1     779,33\n",
      "2     779,33\n",
      "3     798,91\n",
      "4     798,91\n",
      "5     798,91\n",
      "6     798,91\n",
      "7    1295,39\n",
      "8    1295,39\n",
      "9    1295,39\n",
      "Name: area_terreno, dtype: object\n",
      "0     511,0\n",
      "1    582,44\n",
      "2    582,44\n",
      "3    118,55\n",
      "4    118,64\n",
      "5    118,64\n",
      "6    118,55\n",
      "7    145,68\n",
      "8     145,8\n",
      "9    145,49\n",
      "Name: area_construida, dtype: object\n",
      "0        1,0\n",
      "1        1,0\n",
      "2        1,0\n",
      "3    0,02516\n",
      "4    0,02518\n",
      "5    0,02518\n",
      "6    0,02516\n",
      "7    0,01586\n",
      "8    0,01589\n",
      "9    0,01581\n",
      "Name: fracao_ideal, dtype: object\n",
      "0       M√©dio\n",
      "1       M√©dio\n",
      "2       M√©dio\n",
      "3       M√©dio\n",
      "4       M√©dio\n",
      "5       M√©dio\n",
      "6       M√©dio\n",
      "7    Superior\n",
      "8    Superior\n",
      "9    Superior\n",
      "Name: padrao_acabamento, dtype: object\n",
      "0                        Galp√£o\n",
      "1                          Casa\n",
      "2                          Casa\n",
      "3    Apartamento > 4 Pavimentos\n",
      "4    Apartamento > 4 Pavimentos\n",
      "5    Apartamento > 4 Pavimentos\n",
      "6    Apartamento > 4 Pavimentos\n",
      "7    Apartamento > 4 Pavimentos\n",
      "8    Apartamento > 4 Pavimentos\n",
      "9    Apartamento > 4 Pavimentos\n",
      "Name: tipo_construcao, dtype: object\n",
      "0    COMERCIAL COM LIXO ORGANICO\n",
      "1    COMERCIAL SEM LIXO ORGANICO\n",
      "2    COMERCIAL SEM LIXO ORGANICO\n",
      "3                    RESIDENCIAL\n",
      "4                    RESIDENCIAL\n",
      "5                    RESIDENCIAL\n",
      "6                    RESIDENCIAL\n",
      "7                    RESIDENCIAL\n",
      "8                    RESIDENCIAL\n",
      "9                    RESIDENCIAL\n",
      "Name: tipo_ocupacao, dtype: object\n",
      "0    2024-01-23\n",
      "1    2024-01-25\n",
      "2    2024-01-05\n",
      "3    2024-10-22\n",
      "4    2024-05-15\n",
      "5    2024-08-05\n",
      "6    2024-05-22\n",
      "7    2024-04-15\n",
      "8    2024-07-26\n",
      "9    2024-02-01\n",
      "Name: data_transacao, dtype: object\n",
      "0    Regular\n",
      "1    Regular\n",
      "2    Regular\n",
      "3        Bom\n",
      "4        Bom\n",
      "5        Bom\n",
      "6        Bom\n",
      "7        Bom\n",
      "8        Bom\n",
      "9        Bom\n",
      "Name: estado_conservacao, dtype: object\n",
      "0         Galp√£o\n",
      "1           Casa\n",
      "2           Casa\n",
      "3    Apartamento\n",
      "4    Apartamento\n",
      "5    Apartamento\n",
      "6    Apartamento\n",
      "7    Apartamento\n",
      "8    Apartamento\n",
      "9    Apartamento\n",
      "Name: tipo_imovel, dtype: object\n",
      "0         0,00\n",
      "1         0,00\n",
      "2         0,00\n",
      "3    200000,00\n",
      "4    288000,00\n",
      "5    235000,00\n",
      "6         0,00\n",
      "7         0,00\n",
      "8    665000,00\n",
      "9         0,00\n",
      "Name: valores_financiados_sfh, dtype: object\n",
      "0    46540\n",
      "1    46540\n",
      "2    46540\n",
      "3    13269\n",
      "4    13269\n",
      "5    13269\n",
      "6    13269\n",
      "7    13269\n",
      "8    13269\n",
      "9    13269\n",
      "Name: cod_logradouro, dtype: int64\n",
      "0   -8.034273\n",
      "1   -8.034435\n",
      "2   -8.034435\n",
      "3   -8.034996\n",
      "4   -8.034996\n",
      "5   -8.034996\n",
      "6   -8.034996\n",
      "7         NaN\n",
      "8         NaN\n",
      "9         NaN\n",
      "Name: latitude, dtype: float64\n",
      "0   -34.896337\n",
      "1   -34.896335\n",
      "2   -34.896335\n",
      "3   -34.896187\n",
      "4   -34.896187\n",
      "5   -34.896187\n",
      "6   -34.896187\n",
      "7          NaN\n",
      "8          NaN\n",
      "9          NaN\n",
      "Name: longitude, dtype: float64\n",
      "0    2024\n",
      "1    2024\n",
      "2    2024\n",
      "3    2024\n",
      "4    2024\n",
      "5    2024\n",
      "6    2024\n",
      "7    2024\n",
      "8    2024\n",
      "9    2024\n",
      "Name: ano, dtype: int64\n",
      "0    2024\n",
      "1    2024\n",
      "2    2024\n",
      "3    2024\n",
      "4    2024\n",
      "5    2024\n",
      "6    2024\n",
      "7    2024\n",
      "8    2024\n",
      "9    2024\n",
      "Name: year, dtype: int64\n",
      "0          rua caio pereira\n",
      "1          rua caio pereira\n",
      "2          rua caio pereira\n",
      "3          rua caio pereira\n",
      "4          rua caio pereira\n",
      "5          rua caio pereira\n",
      "6     rua doutor jose maria\n",
      "7     rua doutor jose maria\n",
      "8        rua andre reboucas\n",
      "9    rua engenheiro sampaio\n",
      "Name: logradouro, dtype: object\n",
      "0    375\n",
      "1    375\n",
      "2    800\n",
      "3    800\n",
      "4    800\n",
      "5    334\n",
      "6    578\n",
      "7    658\n",
      "8    106\n",
      "9     68\n",
      "Name: numero, dtype: int64\n",
      "0     apto 803 edf luar do rosarinho\n",
      "1     apto 302 edf luar do rosarinho\n",
      "2       apto 1201 edf sainte juliana\n",
      "3       apto 1501 edf sainte juliana\n",
      "4       apto 1602 edf sainte juliana\n",
      "5     apto 202 edf essenza rosarinho\n",
      "6       apto 0102 edf praia de ceres\n",
      "7          apto 1701 edf casa rosada\n",
      "8    apto 302 edf bellagio residence\n",
      "9        apto 404 splendid rosarinho\n",
      "Name: complemento, dtype: object\n",
      "0     505000,00\n",
      "1     398109,72\n",
      "2     790000,00\n",
      "3     780000,00\n",
      "4     840000,00\n",
      "5    1000000,00\n",
      "6     595739,42\n",
      "7     600000,00\n",
      "8     230000,00\n",
      "9     300000,00\n",
      "Name: valor_avaliacao, dtype: object\n",
      "0    Encruzilhada\n",
      "1    Encruzilhada\n",
      "2    Encruzilhada\n",
      "3    Encruzilhada\n",
      "4    Encruzilhada\n",
      "5    Encruzilhada\n",
      "6    Encruzilhada\n",
      "7    Encruzilhada\n",
      "8       Rosarinho\n",
      "9       Rosarinho\n",
      "Name: bairro, dtype: object\n",
      "0    2007\n",
      "1    2007\n",
      "2    2017\n",
      "3    2017\n",
      "4    2017\n",
      "5    2011\n",
      "6    2002\n",
      "7    2010\n",
      "8    2015\n",
      "9    2014\n",
      "Name: ano_construcao, dtype: int64\n",
      "0     798,91\n",
      "1     798,91\n",
      "2    1295,39\n",
      "3    1295,39\n",
      "4    1295,39\n",
      "5    1737,63\n",
      "6      861,0\n",
      "7     3090,5\n",
      "8     610,36\n",
      "9    2202,75\n",
      "Name: area_terreno, dtype: object\n",
      "0    132,01\n",
      "1    118,64\n",
      "2    145,68\n",
      "3    145,68\n",
      "4     145,8\n",
      "5     183,6\n",
      "6    184,77\n",
      "7    244,73\n",
      "8     59,74\n",
      "9     59,93\n",
      "Name: area_construida, dtype: object\n",
      "0    0,02698\n",
      "1    0,02518\n",
      "2    0,01586\n",
      "3    0,01586\n",
      "4    0,01589\n",
      "5    0,01923\n",
      "6    0,03333\n",
      "7    0,01401\n",
      "8    0,02165\n",
      "9    0,00727\n",
      "Name: fracao_ideal, dtype: object\n",
      "0       M√©dio\n",
      "1       M√©dio\n",
      "2    Superior\n",
      "3    Superior\n",
      "4    Superior\n",
      "5    Superior\n",
      "6    Superior\n",
      "7    Superior\n",
      "8       M√©dio\n",
      "9    Superior\n",
      "Name: padrao_acabamento, dtype: object\n",
      "0    Apartamento > 4 Pavimentos\n",
      "1    Apartamento > 4 Pavimentos\n",
      "2    Apartamento > 4 Pavimentos\n",
      "3    Apartamento > 4 Pavimentos\n",
      "4    Apartamento > 4 Pavimentos\n",
      "5    Apartamento > 4 Pavimentos\n",
      "6    Apartamento > 4 Pavimentos\n",
      "7    Apartamento > 4 Pavimentos\n",
      "8    Apartamento > 4 Pavimentos\n",
      "9    Apartamento > 4 Pavimentos\n",
      "Name: tipo_construcao, dtype: object\n",
      "0    RESIDENCIAL\n",
      "1    RESIDENCIAL\n",
      "2    RESIDENCIAL\n",
      "3    RESIDENCIAL\n",
      "4    RESIDENCIAL\n",
      "5    RESIDENCIAL\n",
      "6    RESIDENCIAL\n",
      "7    RESIDENCIAL\n",
      "8    RESIDENCIAL\n",
      "9    RESIDENCIAL\n",
      "Name: tipo_ocupacao, dtype: object\n",
      "0    2025-01-08\n",
      "1    2025-05-12\n",
      "2    2025-04-14\n",
      "3    2025-01-08\n",
      "4    2025-01-14\n",
      "5    2025-01-14\n",
      "6    2025-01-08\n",
      "7    2025-04-09\n",
      "8    2025-04-16\n",
      "9    2025-05-23\n",
      "Name: data_transacao, dtype: object\n",
      "0    Bom\n",
      "1    Bom\n",
      "2    Bom\n",
      "3    Bom\n",
      "4    Bom\n",
      "5    Bom\n",
      "6    Bom\n",
      "7    Bom\n",
      "8    Bom\n",
      "9    Bom\n",
      "Name: estado_conservacao, dtype: object\n",
      "0    Apartamento\n",
      "1    Apartamento\n",
      "2    Apartamento\n",
      "3    Apartamento\n",
      "4    Apartamento\n",
      "5    Apartamento\n",
      "6    Apartamento\n",
      "7    Apartamento\n",
      "8    Apartamento\n",
      "9    Apartamento\n",
      "Name: tipo_imovel, dtype: object\n",
      "0         0,00\n",
      "1         0,00\n",
      "2         0,00\n",
      "3         0,00\n",
      "4    565600,32\n",
      "5         0,00\n",
      "6         0,00\n",
      "7         0,00\n",
      "8         0,00\n",
      "9         0,00\n",
      "Name: valores_financiados_sfh, dtype: object\n",
      "0    13269\n",
      "1    13269\n",
      "2    13269\n",
      "3    13269\n",
      "4    13269\n",
      "5    13269\n",
      "6    36196\n",
      "7    36196\n",
      "8     4928\n",
      "9    53627\n",
      "Name: cod_logradouro, dtype: int64\n",
      "0   -8.034996\n",
      "1   -8.034996\n",
      "2         NaN\n",
      "3         NaN\n",
      "4         NaN\n",
      "5   -8.035095\n",
      "6   -8.035868\n",
      "7   -8.035419\n",
      "8   -8.032817\n",
      "9   -8.033695\n",
      "Name: latitude, dtype: float64\n",
      "0   -34.896187\n",
      "1   -34.896187\n",
      "2          NaN\n",
      "3          NaN\n",
      "4          NaN\n",
      "5   -34.896937\n",
      "6   -34.896250\n",
      "7   -34.897024\n",
      "8   -34.897594\n",
      "9   -34.897214\n",
      "Name: longitude, dtype: float64\n",
      "0    2025\n",
      "1    2025\n",
      "2    2025\n",
      "3    2025\n",
      "4    2025\n",
      "5    2025\n",
      "6    2025\n",
      "7    2025\n",
      "8    2025\n",
      "9    2025\n",
      "Name: ano, dtype: int64\n",
      "0    2025\n",
      "1    2025\n",
      "2    2025\n",
      "3    2025\n",
      "4    2025\n",
      "5    2025\n",
      "6    2025\n",
      "7    2025\n",
      "8    2025\n",
      "9    2025\n",
      "Name: year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for year, df in datasets_dict.items():\n",
    "\n",
    "    for i in range(len(df.columns)):\n",
    "        col_name = df.columns[i]\n",
    "        print(df[col_name].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35edf729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA TYPE CONVERSION: VALOR_AVALIACAO TO FLOAT\n",
    "# We will convert the 'valor_avaliacao' column from object type to float to enable proper\n",
    "# numerical operations and statistical analysis. Currently stored as object (string), this\n",
    "# prevents mathematical calculations, aggregations, and numeric comparisons essential for\n",
    "# financial analysis of property values. Converting to float ensures data integrity and\n",
    "# enables accurate computation of means, sums, and other statistical measures for ITBI values.\n",
    "\n",
    "\n",
    "\n",
    "# DECIMAL SEPARATOR STANDARDIZATION FUNCTION\n",
    "# Converts Brazilian decimal format (comma) to international format (dot) required for float conversion\n",
    "def standardize_decimal_format(x):\n",
    "    new = str(x.replace(',','.'))\n",
    "    return new\n",
    "    \n",
    "# STEP 1: Replace commas with dots to prepare for float conversion\n",
    "for year, df in datasets_dict.items():\n",
    "    df['valor_avaliacao'] = df['valor_avaliacao'].apply(standardize_decimal_format)\n",
    "    datasets_dict[year] = df\n",
    "\n",
    "# STEP 2: Convert standardized strings to float type for numerical operations\n",
    "for year, df in datasets_dict.items():\n",
    "    df['valor_avaliacao'] = df['valor_avaliacao'].astype('float')\n",
    "    datasets_dict[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a86796e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AREA_TERRENO CONVERSION: APPLYING SAME DECIMAL STANDARDIZATION PROCESS\n",
    "# The 'area_terreno' column requires identical treatment as 'valor_avaliacao' - converting\n",
    "# Brazilian decimal format (comma) to international format (dot) before float conversion.\n",
    "# This ensures consistent numerical data types across all measurement columns for analysis.\n",
    "\n",
    "for year, df in datasets_dict.items():\n",
    "    df['area_terreno'] = df['area_terreno'].astype(str).str.replace(',', '.').astype(float)\n",
    "    df['area_terreno'] = df['area_terreno'].astype('float')\n",
    "    datasets_dict[year] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e39196ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AREA_CONSTRUIDA CONVERSION: SAME DECIMAL STANDARDIZATION PROCESS\n",
    "# Converting 'area_construida' from Brazilian decimal format (comma) to international format (dot)\n",
    "for year, df in datasets_dict.items():\n",
    "    df['area_construida'] = df['area_construida'].astype(str).str.replace(',', '.').astype(float)\n",
    "    df['area_construida'] = df['area_construida'].astype('float')\n",
    "    datasets_dict[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eea3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        M√©dio\n",
      "1        M√©dio\n",
      "2      Simples\n",
      "3      Simples\n",
      "4      Simples\n",
      "5      Simples\n",
      "6      Simples\n",
      "7      Simples\n",
      "8        M√©dio\n",
      "9        M√©dio\n",
      "10    Superior\n",
      "11    Superior\n",
      "12    Superior\n",
      "13       M√©dio\n",
      "14    Superior\n",
      "15    Superior\n",
      "16    Superior\n",
      "17    Superior\n",
      "18    Superior\n",
      "19    Superior\n",
      "Name: padrao_acabamento, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ENCODING CORRECTION: FIXING INCORRECTLY ENCODED CHARACTERS\n",
    "# Brazilian datasets often contain encoding issues where Portuguese characters (√£, √ß, √™, √µ, etc.) \n",
    "# are incorrectly displayed due to mismatched character encoding during data extraction.\n",
    "# This commonly occurs when CSV files are saved with Latin1 (ISO-8859-1) encoding but read as UTF-8,\n",
    "# causing characters like \"√ß√£o\" to appear as \"√É¬ß√É¬£o\" or similar garbled text.\n",
    "# We fix this by re-encoding the text: first encode as Latin1 then decode as UTF-8 to restore\n",
    "# the original Portuguese characters for proper data analysis and visualization.\n",
    "\n",
    "def fix_encoding_issues(text_value):\n",
    "    if not isinstance(text_value, str):\n",
    "        return text_value\n",
    "    try:\n",
    "        return text_value.encode('latin1').decode('utf-8')\n",
    "    except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "        return text_value\n",
    "\n",
    "# Apply encoding correction to all text columns in all datasets\n",
    "for year, df in datasets_dict.items():\n",
    "    text_columns = df.select_dtypes(include=['object']).columns\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].apply(fix_encoding_issues)\n",
    "    datasets_dict[year] = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79131f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
