{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62178a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e202c2d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810ff5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries required to clean, standardize, and prepare the dataset for futher analysis.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "start_time  = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17276e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ AGGRESSIVE MEMORY CLEANUP STARTING...\n",
      "üßπ AGGRESSIVE MEMORY CLEANUP COMPLETED\n",
      "==================================================\n",
      "üè† LOADING ITBI DATASETS FROM RECIFE\n",
      "==================================================\n",
      "\n",
      "üìÖ Loading ITBI 2023 data...\n",
      "   ‚úÖ Success: 12,669 records, 23 columns\n",
      "\n",
      "üìÖ Loading ITBI 2024 data...\n",
      "   ‚úÖ Success: 12,669 records, 23 columns\n",
      "\n",
      "üìÖ Loading ITBI 2024 data...\n",
      "   ‚úÖ Success: 15,242 records, 23 columns\n",
      "\n",
      "üìÖ Loading ITBI 2025 data...\n",
      "   ‚úÖ Success: 15,242 records, 23 columns\n",
      "\n",
      "üìÖ Loading ITBI 2025 data...\n",
      "   ‚úÖ Success: 7,206 records, 23 columns\n",
      "\n",
      "üîç VERIFICATION\n",
      "--------------------\n",
      "   ‚Ä¢ Total datasets loaded: 3\n",
      "   ‚Ä¢ Years loaded: ['2023', '2024', '2025']\n",
      "\n",
      "üîó COMBINING DATASETS\n",
      "------------------------------\n",
      "üìä FINAL DATASET SUMMARY\n",
      "==============================\n",
      "   ‚Ä¢ Total records: 35,117\n",
      "   ‚Ä¢ Total columns: 23\n",
      "   ‚Ä¢ Years included: [np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "   ‚Ä¢ Memory usage: 33.72 MB\n",
      "\n",
      "üìà Records by year:\n",
      "   ‚Ä¢ 2023: 12,669 records\n",
      "   ‚Ä¢ 2024: 15,242 records\n",
      "   ‚Ä¢ 2025: 7,206 records\n",
      "\n",
      "üìã Sample data (first 3 rows):\n",
      "   year        bairro  tipo_imovel valor_avaliacao data_transacao\n",
      "0  2023  Encruzilhada       Galp√£o      1068562,63     2023-12-21\n",
      "1  2023  Encruzilhada         Casa      1500000,00     2023-11-17\n",
      "2  2023  Encruzilhada  Apartamento       110000,00     2023-09-26\n",
      "\n",
      "‚úÖ Directory \"datasets\" is ready for use.\n",
      "‚úÖ ETL Extract phase completed successfully!\n",
      "   ‚úÖ Success: 7,206 records, 23 columns\n",
      "\n",
      "üîç VERIFICATION\n",
      "--------------------\n",
      "   ‚Ä¢ Total datasets loaded: 3\n",
      "   ‚Ä¢ Years loaded: ['2023', '2024', '2025']\n",
      "\n",
      "üîó COMBINING DATASETS\n",
      "------------------------------\n",
      "üìä FINAL DATASET SUMMARY\n",
      "==============================\n",
      "   ‚Ä¢ Total records: 35,117\n",
      "   ‚Ä¢ Total columns: 23\n",
      "   ‚Ä¢ Years included: [np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "   ‚Ä¢ Memory usage: 33.72 MB\n",
      "\n",
      "üìà Records by year:\n",
      "   ‚Ä¢ 2023: 12,669 records\n",
      "   ‚Ä¢ 2024: 15,242 records\n",
      "   ‚Ä¢ 2025: 7,206 records\n",
      "\n",
      "üìã Sample data (first 3 rows):\n",
      "   year        bairro  tipo_imovel valor_avaliacao data_transacao\n",
      "0  2023  Encruzilhada       Galp√£o      1068562,63     2023-12-21\n",
      "1  2023  Encruzilhada         Casa      1500000,00     2023-11-17\n",
      "2  2023  Encruzilhada  Apartamento       110000,00     2023-09-26\n",
      "\n",
      "‚úÖ Directory \"datasets\" is ready for use.\n",
      "‚úÖ ETL Extract phase completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path where datasets will be stored\n",
    "dataset_directory = \"datasets\"\n",
    "\n",
    "# Create the directory if it doesn't exist, avoiding errors if it already exists\n",
    "os.makedirs(dataset_directory, exist_ok=True)\n",
    "\n",
    "# AGGRESSIVE MEMORY CLEANUP - Remove ALL potentially interfering variables\n",
    "import gc\n",
    "\n",
    "# Get current namespace\n",
    "current_vars = list(globals().keys())\n",
    "\n",
    "# Clean EVERYTHING except essential modules\n",
    "protected_vars = ['__builtins__', '__name__', '__doc__', '__package__', \n",
    "                 '__loader__', '__spec__', '__annotations__', '__cached__',\n",
    "                 'np', 'pd', 'os', 'datetime', 'time', 'zipfile', 'gc',\n",
    "                 'dataset_directory', 'current_vars', 'protected_vars']\n",
    "\n",
    "for var in current_vars:\n",
    "    if var not in protected_vars and not var.startswith('_'):\n",
    "        try:\n",
    "            del globals()[var]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Multiple garbage collections to ensure cleanup\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "\n",
    "print(\"üßπ AGGRESSIVE MEMORY CLEANUP COMPLETED\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define URLs as a simple list to avoid any dictionary issues\n",
    "dataset_info = [\n",
    "    (\"2023\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/d0c08a6f-4c27-423c-9219-8d13403816f4/download/itbi_2023.csv\"),\n",
    "    (\"2024\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/a36d548b-d705-496a-ac47-4ec36f068474/download/itbi_2024.csv\"),\n",
    "    (\"2025\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/5b582147-3935-459a-bbf7-ee623c22c97b/download/itbi_2025.csv\")\n",
    "]\n",
    "\n",
    "print(\"üè† LOADING ITBI DATASETS FROM RECIFE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Store dataframes in a simple list instead of dictionary\n",
    "loaded_dataframes = []\n",
    "loaded_years = []\n",
    "\n",
    "# Load each dataset one by one\n",
    "for year_str, csv_url in dataset_info:\n",
    "    print(f\"\\nüìÖ Loading ITBI {year_str} data...\")\n",
    "    \n",
    "    try:\n",
    "        # Load data with explicit parameters\n",
    "        current_df = pd.read_csv(csv_url, sep=';', encoding='utf-8')\n",
    "        \n",
    "        # Add year column\n",
    "        current_df['year'] = int(year_str)\n",
    "        \n",
    "        # Append to lists\n",
    "        loaded_dataframes.append(current_df)\n",
    "        loaded_years.append(year_str)\n",
    "        \n",
    "        print(f\"   ‚úÖ Success: {len(current_df):,} records, {len(current_df.columns)} columns\")\n",
    "        \n",
    "        # Explicitly delete the temporary dataframe\n",
    "        del current_df\n",
    "        \n",
    "    except Exception as error:\n",
    "        print(f\"   ‚ùå Error loading {year_str} data: {error}\")\n",
    "\n",
    "# Verification step\n",
    "print(f\"\\nüîç VERIFICATION\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"   ‚Ä¢ Total datasets loaded: {len(loaded_dataframes)}\")\n",
    "print(f\"   ‚Ä¢ Years loaded: {loaded_years}\")\n",
    "\n",
    "# Only proceed if we have exactly 3 datasets\n",
    "if len(loaded_dataframes) == 3:\n",
    "    print(f\"\\nüîó COMBINING DATASETS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Combine dataframes\n",
    "    final_df = pd.concat(loaded_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Clear the list to free memory\n",
    "    loaded_dataframes.clear()\n",
    "    \n",
    "    print(f\"üìä FINAL DATASET SUMMARY\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"   ‚Ä¢ Total records: {len(final_df):,}\")\n",
    "    print(f\"   ‚Ä¢ Total columns: {len(final_df.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Years included: {sorted(final_df['year'].unique())}\")\n",
    "    print(f\"   ‚Ä¢ Memory usage: {final_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Records by year\n",
    "    print(f\"\\nüìà Records by year:\")\n",
    "    records_by_year = final_df['year'].value_counts().sort_index()\n",
    "    for year_num, record_count in records_by_year.items():\n",
    "        print(f\"   ‚Ä¢ {year_num}: {record_count:,} records\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample data (first 3 rows):\")\n",
    "    sample_columns = ['year', 'bairro', 'tipo_imovel', 'valor_avaliacao', 'data_transacao']\n",
    "    print(final_df[sample_columns].head(3))\n",
    "    \n",
    "    # Store final dataframe in standard variable name\n",
    "    df = final_df\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ùå ERROR: Expected exactly 3 datasets, but loaded {len(loaded_dataframes)}\")\n",
    "    print(\"   Cannot proceed with data combination.\")\n",
    "\n",
    "print(f'\\n‚úÖ Directory \"{dataset_directory}\" is ready for use.')\n",
    "print(\"‚úÖ ETL Extract phase completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
